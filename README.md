# A Multimodal AI Copilot for Interactive and Scalable Cytology
Official PyTorch implementation of the paper "A Multimodal AI Copilot for Interactive and Scalable Cytology" and the model will be coming soon. ðŸŽˆ

## Overview

<img src="assets/banner.png" alt="Overview" width="1000px">

Foundation models are shifting the paradigm from task-specific pipelines toward interactive diagnostic copilots. Cytology, one of the highest-volume and most labor-intensive domains in pathology, has yet to fully benefit from these advances. Here we present CytoChat, the first multimodal generative AI copilot purpose-built for cytopathology. CytoChat was trained on more than 1.2 million instruction-answer pairs curated from over 650,000 public and private image-caption pairs, encompassing diverse task formats such as visual question answering, multi-turn dialogue, descriptive reporting, multiple-choice reasoning, multi-cell grounding, and referring expression comprehension. To enable rigorous evaluation, we curated and publicly released a high-quality cytology benchmark that integrates data from both private and public sources, spans the full spectrum of instruction formats, and enables direct comparison with five state-of-the-art large language model baselines. At the patch level, CytoChat outperformed all baselines across tasks, achieving an average multiple-choice accuracy of 71.0% and exceeding others by 18.5% to 41.1%. Patch-level predictions were further aggregated into robust slide-level assessments. By bridging visual understanding with multimodal reasoning and interactive guidance, CytoChat lays the foundation for next-generation cytopathology, enabling more accurate, reproducible, and collaborative diagnostics at scale. 